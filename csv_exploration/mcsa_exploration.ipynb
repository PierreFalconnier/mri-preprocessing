{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56cea0a2",
   "metadata": {},
   "source": [
    "The objectives of the Mayo Clinic Study of Aging were to determine in the population of Olmsted County, Minn., (1) the prevalence of MCI; (2) the incidence of MCI; (3) conversion rates from MCI to dementia or AD; (4) risk factors for MCI; and (5) risk factors for the progression from MCI to dementia or AD. The long-term goals of the Mayo Clinic Study of Aging are to develop tools to predict and prevent cognitive decline and dementia, develop risk-prediction models for cognitive impairment, and conduct aging-related research to promote successful aging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2989436",
   "metadata": {},
   "source": [
    "# Setup and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3345b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0: get current notebook path, its parent, and project root (parent of parent)\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Optional: improve plots appearance\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "ROOT_DIR = Path(os.getcwd()).resolve().parent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc4ff3",
   "metadata": {},
   "source": [
    "# Load the CSV and parse Imaging Protocol + merge with other MCSA csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9867900",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_DIR = ROOT_DIR / \"csv_dir\"\n",
    "df1 = pd.read_csv(CSV_DIR / \"MCSA_all.csv\")\n",
    "df2 = pd.read_csv(CSV_DIR / \"MCSA_Data.csv\")\n",
    "\n",
    "df1[\"Subject ID\"] = df1[\"Subject ID\"].astype(str)\n",
    "df2[\"MCSA_ID\"] = df2[\"MCSA_ID\"].astype(str)\n",
    "\n",
    "df1[\"Visit\"] = pd.to_numeric(df1[\"Visit\"], errors=\"coerce\")\n",
    "df2[\"visit_num\"] = pd.to_numeric(df2[\"visit_num\"], errors=\"coerce\")\n",
    "\n",
    "original_df = pd.merge(\n",
    "    df1,\n",
    "    df2,\n",
    "    left_on=[\"Subject ID\", \"Visit\"],\n",
    "    right_on=[\"MCSA_ID\", \"visit_num\"],\n",
    "    how=\"left\",\n",
    "    indicator=True,\n",
    ")\n",
    "\n",
    "print(original_df[\"_merge\"].value_counts())\n",
    "\n",
    "# drop unnecessary columns and rename others\n",
    "original_df = original_df.drop(columns=[\"_merge\", \"MCSA_ID\", \"visit_num\"])\n",
    "original_df = original_df.drop(columns=[\"Age\"]).rename(columns={\"calc_age_vis\": \"Age\"})\n",
    "original_df = original_df.drop(columns=[\"Sex\"]).rename(columns={\"Male\": \"Sex\"})\n",
    "\n",
    "\n",
    "# little adjustments\n",
    "original_df[\"Subject ID\"] = original_df[\"Subject ID\"].astype(\"category\")\n",
    "original_df[\"Image ID\"] = original_df[\"Image ID\"].astype(\"category\")\n",
    "original_df[\"Weight\"] = original_df[\"Weight\"].replace(0, np.nan)\n",
    "original_df[\"Age\"] = original_df[\"Age\"].replace(0, np.nan)\n",
    "original_df[\"Study Date\"] = pd.to_datetime(original_df[\"Study Date\"], errors=\"coerce\")\n",
    "\n",
    "print(original_df.columns)\n",
    "print(len(original_df))\n",
    "\n",
    "fields = [\n",
    "    \"Acquisition Plane\",\n",
    "    \"Slice Thickness\",\n",
    "    \"Matrix Z\",\n",
    "    \"Acquisition Type\",\n",
    "    \"Manufacturer\",\n",
    "    \"Mfg Model\",\n",
    "    \"Field Strength\",\n",
    "    \"Weighting\",\n",
    "]\n",
    "\n",
    "numeric_fields = [\"Slice Thickness\", \"Matrix Z\", \"Field Strength\"]\n",
    "\n",
    "\n",
    "def parse_imaging_protocol(text):\n",
    "    if pd.isna(text):\n",
    "        return {}\n",
    "\n",
    "    items = text.split(\";\")\n",
    "    parsed = {}\n",
    "\n",
    "    for item in items:\n",
    "        if \"=\" in item:\n",
    "            key, value = item.split(\"=\", 1)\n",
    "            parsed[key.strip()] = value.strip()\n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "# Parse the column into dictionaries\n",
    "protocol_parsed = original_df[\"Imaging Protocol\"].apply(parse_imaging_protocol)\n",
    "\n",
    "# Create new columns\n",
    "for field in fields:\n",
    "    original_df[field] = protocol_parsed.apply(lambda x: x.get(field, np.nan))\n",
    "\n",
    "\n",
    "for field in numeric_fields:\n",
    "    original_df[field] = pd.to_numeric(original_df[field], errors=\"coerce\")\n",
    "\n",
    "print(original_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea7d7d",
   "metadata": {},
   "source": [
    "# Filtered dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ca1c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filters\n",
    "weighting_filter = original_df[\"Weighting\"] == \"T1\"\n",
    "\n",
    "df = original_df[\n",
    "    (original_df[\"Modality\"] == \"MRI\")\n",
    "    & weighting_filter\n",
    "    & (original_df[\"Matrix Z\"] > 100)\n",
    "    & (original_df[\"Slice Thickness\"] < 1.4)\n",
    "    & (original_df[\"Acquisition Type\"] == \"3D\")\n",
    "    & (original_df[\"Type\"] == \"Original\")\n",
    "].copy()\n",
    "\n",
    "print(\n",
    "    f\"Filtered dataset size: {df.shape[0]} images from {df['Subject ID'].nunique()} subjects.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae81a24",
   "metadata": {},
   "source": [
    "### No filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb28cd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = original_df\n",
    "# print(\n",
    "#     f\"Filtered dataset size: {df.shape[0]} images from {df['Subject ID'].nunique()} subjects.\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a1da01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688719e1",
   "metadata": {},
   "source": [
    "# Basic descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f497517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Column Names\n",
    "# -------------------------------\n",
    "print(\"=== Columns in the Dataset ===\")\n",
    "display(pd.DataFrame(df.columns, columns=[\"Column Names\"]))\n",
    "\n",
    "# -------------------------------\n",
    "# Summary of Numeric Features\n",
    "# -------------------------------\n",
    "print(\"\\n=== Numeric Features Summary ===\")\n",
    "display(df.describe().round(2))  # round to 2 decimals\n",
    "\n",
    "# -------------------------------\n",
    "# Summary of Categorical Features\n",
    "# -------------------------------\n",
    "print(\"\\n=== Categorical Features Summary ===\")\n",
    "display(df.describe(include=[\"object\", \"category\"]))\n",
    "\n",
    "# -------------------------------\n",
    "# Missing Values\n",
    "# -------------------------------\n",
    "missing_count = df.isnull().sum()\n",
    "missing_percent = (missing_count / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame(\n",
    "    {\"Missing Count\": missing_count, \"Missing %\": missing_percent}\n",
    ").sort_values(by=\"Missing Count\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Missing Values by Column ===\")\n",
    "display(missing_df)\n",
    "\n",
    "# Find columns with at least one missing value\n",
    "cols_with_missing = df.columns[df.isnull().any()]\n",
    "print(f\"Columns with missing values ({len(cols_with_missing)}):\\n\")\n",
    "\n",
    "# for col in cols_with_missing:\n",
    "#     print(f\"--- {col} ---\")\n",
    "#     # Show up to 5 rows where this column is missing\n",
    "#     display(df[df[col].isnull()].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac8e51f",
   "metadata": {},
   "source": [
    "# Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4207c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric and categorical columns\n",
    "numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "categorical_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "# -------------------------------\n",
    "# Numeric Columns Histograms\n",
    "# -------------------------------\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Plot histogram\n",
    "    ax = sns.histplot(\n",
    "        df[col].dropna(), bins=30, kde=False\n",
    "    )  # disable KDE for counts clarity\n",
    "\n",
    "    plt.title(f\"Histogram of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "\n",
    "    # Annotate counts on top of each bin\n",
    "    for patch in ax.patches:\n",
    "        height = patch.get_height()\n",
    "        if height > 0:  # only annotate non-empty bins\n",
    "            ax.text(\n",
    "                patch.get_x() + patch.get_width() / 2,  # center of bin\n",
    "                height + 0.5,  # slightly above the bar\n",
    "                int(height),  # show integer count\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# Categorical Columns Bar Plots\n",
    "# -------------------------------\n",
    "categorical_cols = [\n",
    "    \"Visit\",\n",
    "    \"Sex\",\n",
    "    \"Research Group\",\n",
    "    \"Modality\",\n",
    "    \"Type\",\n",
    "    \"Structure\",\n",
    "    \"Laterality\",\n",
    "    \"Image Type\",\n",
    "    \"Registration\",\n",
    "    \"Description\",\n",
    "    \"Tissue\",\n",
    "    # Imaging Protocolâ€“derived categorical columns\n",
    "    \"Acquisition Plane\",\n",
    "    \"Acquisition Type\",\n",
    "    # \"Manufacturer\",\n",
    "    # \"Mfg Model\",\n",
    "    \"Weighting\",\n",
    "]\n",
    "\n",
    "categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    counts = df[col].value_counts(dropna=False)\n",
    "    total = counts.sum()\n",
    "    order = counts.index\n",
    "\n",
    "    ax = sns.countplot(y=col, data=df, order=order)\n",
    "\n",
    "    # Add count + percentage labels\n",
    "    for p, category in zip(ax.patches, order):\n",
    "        count = counts[category]\n",
    "        percent = 100 * count / total\n",
    "\n",
    "        ax.text(\n",
    "            p.get_width() + 0.5,\n",
    "            p.get_y() + p.get_height() / 2,\n",
    "            f\"{count} ({percent:.1f}%)\",\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "    plt.title(f\"Value Counts for {col}\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2a2c6c",
   "metadata": {},
   "source": [
    "# Study dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Study Date Distribution\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Histogram of study dates\n",
    "ax = sns.histplot(df[\"Study Date\"].dropna(), bins=30, kde=False)\n",
    "\n",
    "plt.title(\"Distribution of Study Dates\")\n",
    "plt.xlabel(\"Study Date\")\n",
    "plt.ylabel(\"Number of Studies\")\n",
    "\n",
    "# Annotate counts on top of each bin\n",
    "for patch in ax.patches:\n",
    "    height = patch.get_height()\n",
    "    if height > 0:\n",
    "        ax.text(\n",
    "            patch.get_x() + patch.get_width() / 2,\n",
    "            height + 0.5,\n",
    "            int(height),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=8,\n",
    "        )\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# cumulative study count over time\n",
    "plt.figure(figsize=(10, 4))\n",
    "df_sorted = df.sort_values(\"Study Date\")\n",
    "df_sorted[\"Cumulative Count\"] = range(1, len(df_sorted) + 1)\n",
    "plt.plot(\n",
    "    df_sorted[\"Study Date\"], df_sorted[\"Cumulative Count\"], marker=\"o\", linestyle=\"-\"\n",
    ")\n",
    "plt.title(\"Cumulative Study Count Over Time\")\n",
    "plt.xlabel(\"Study Date\")\n",
    "plt.ylabel(\"Cumulative Count\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dab4f0c",
   "metadata": {},
   "source": [
    "# Scans per session / coverage\n",
    "\n",
    "Does a subject have more than one scan at a given visit?\n",
    "\n",
    "How often does this happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d28f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Visit\"] = df[\"Visit\"].astype(str)\n",
    "\n",
    "# scans per subject per visit\n",
    "scans_per_subject_visit = (\n",
    "    df.groupby([\"Subject ID\", \"Visit\"], observed=True)\n",
    "    .size()\n",
    "    .reset_index(name=\"n_scans\")\n",
    ")\n",
    "# Keep only rows with at least 1 scan\n",
    "scans_per_subject_visit = scans_per_subject_visit[\n",
    "    scans_per_subject_visit[\"n_scans\"] > 0\n",
    "].copy()\n",
    "# print(scans_per_subject_visit.head())\n",
    "# print(scans_per_subject_visit[\"n_scans\"].min())  # should now be >= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.countplot(\n",
    "    x=\"n_scans\",\n",
    "    data=scans_per_subject_visit,\n",
    "    order=sorted(scans_per_subject_visit[\"n_scans\"].unique()),\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Number of Scans per Subject per Visit\")\n",
    "plt.ylabel(\"Number of (Subject, Visit) Sessions\")\n",
    "plt.title(\"Multiplicity of Scans per Session\")\n",
    "\n",
    "# Annotate counts on top of bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        int(p.get_height()),\n",
    "        (p.get_x() + p.get_width() / 2.0, p.get_height()),\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\",\n",
    "    )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb8f0e",
   "metadata": {},
   "source": [
    "# Longitudinal analysis - for filtered subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07640d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Visit\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab958663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Visit to numeric\n",
    "df[\"Visit_Num\"] = pd.to_numeric(df[\"Visit\"], errors=\"coerce\")\n",
    "\n",
    "# Sanity check\n",
    "print(df[\"Visit_Num\"].isna().sum())  # should be 0\n",
    "\n",
    "# Scheduled visits are simply the numeric visit numbers\n",
    "scheduled_visits = sorted(df[\"Visit_Num\"].dropna().unique())\n",
    "\n",
    "print(\"Scheduled Visits:\", scheduled_visits)\n",
    "\n",
    "\n",
    "scheduled_df = df.copy()\n",
    "\n",
    "visits_per_subject = (\n",
    "    scheduled_df.groupby(\"Subject ID\", observed=True)[\"Visit_Num\"]\n",
    "    .nunique()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "# Summary\n",
    "summary_stats = visits_per_subject.describe()\n",
    "print(\"Longitudinal Coverage per Subject:\")\n",
    "display(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72670bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Visit_Num\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387c91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many subjects have N visits -- How many dropouts, How many fully followed subjects, wether dataset is shallow or deep\n",
    "visit_counts = visits_per_subject.value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "ax = sns.barplot(x=visit_counts.index, y=visit_counts.values, palette=\"Blues_d\")\n",
    "\n",
    "# Annotate bars\n",
    "for i, v in enumerate(visit_counts.values):\n",
    "    ax.text(i, v + 0.5, str(v), ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "\n",
    "plt.xlabel(\"Number of Visits\")\n",
    "plt.ylabel(\"Number of Subjects\")\n",
    "plt.title(\"Longitudinal Follow-up Depth\")\n",
    "plt.ylim(0, visit_counts.values.max() * 1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc77fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many subjects remain at each visit -- Where dropout occurs, Which visits are well populated\n",
    "retention = (\n",
    "    scheduled_df.groupby(\"Visit_Num\", observed=True)[\"Subject ID\"]\n",
    "    .nunique()\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(retention.index, retention.values, marker=\"o\")\n",
    "\n",
    "for x, y in zip(retention.index, retention.values):\n",
    "    plt.text(x, y + 0.5, str(y), ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "plt.xlabel(\"Visit Number\")\n",
    "plt.ylabel(\"Number of Active Subjects\")\n",
    "plt.title(\"Subject Retention Over Visits\")\n",
    "plt.grid(True)\n",
    "plt.ylim(0, retention.max() * 1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33389ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Visit is treated as a category so we know the set of visits\n",
    "df[\"Visit_Str\"] = df[\"Visit\"].astype(str)\n",
    "\n",
    "# Sort visit labels numerically (if numeric)\n",
    "try:\n",
    "    sorted_visits = sorted(df[\"Visit_Str\"].unique(), key=lambda x: int(x))\n",
    "except ValueError:\n",
    "    sorted_visits = sorted(df[\"Visit_Str\"].unique())\n",
    "\n",
    "# How many columns/rows for the figure grid\n",
    "n_visits = len(sorted_visits)\n",
    "n_cols = 4  # change if you want wider or narrower layout\n",
    "n_rows = (n_visits + n_cols - 1) // n_cols\n",
    "\n",
    "plt.figure(figsize=(4 * n_cols, 3 * n_rows))\n",
    "\n",
    "for i, visit_label in enumerate(sorted_visits):\n",
    "    ax = plt.subplot(n_rows, n_cols, i + 1)\n",
    "    visit_df = df[df[\"Visit_Str\"] == visit_label]\n",
    "\n",
    "    sns.histplot(visit_df[\"Age\"].dropna(), bins=20, kde=False, ax=ax)\n",
    "    ax.set_title(f\"Visit {visit_label}\")\n",
    "    ax.set_xlabel(\"Age\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_xlim(df[\"Age\"].min(), df[\"Age\"].max())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Age Distribution at Each Visit\", y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
