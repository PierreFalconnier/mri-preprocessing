{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e479681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Neuroimaging\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333189da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_t1w_images(bids_root):\n",
    "    bids_root = Path(bids_root)\n",
    "    t1w_files = list(bids_root.rglob(\"*T1*.nii*\"))\n",
    "    return sorted(t1w_files)\n",
    "\n",
    "\n",
    "def load_json_sidecar(nifti_path):\n",
    "    json_path = nifti_path.with_suffix(\"\").with_suffix(\".json\")\n",
    "    if json_path.exists():\n",
    "        with open(json_path, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "\n",
    "def extract_t1w_stats(nifti_path):\n",
    "    try:\n",
    "        img = nib.load(str(nifti_path))\n",
    "    except Exception as e:\n",
    "        return {\"path\": str(nifti_path), \"error\": str(e)}\n",
    "    header = img.header\n",
    "    sidecar = load_json_sidecar(nifti_path)\n",
    "\n",
    "    # Dimensions\n",
    "    dims = img.shape\n",
    "    voxel_sizes = header.get_zooms()[:3]\n",
    "\n",
    "    # File size (MB)\n",
    "    file_size_mb = nifti_path.stat().st_size / (1024**2)\n",
    "\n",
    "    stats = {\n",
    "        \"subject\": nifti_path.name.split(\"_\")[0],\n",
    "        \"session\": next((p for p in nifti_path.parts if p.startswith(\"ses-\")), None),\n",
    "        \"path\": str(nifti_path),\n",
    "        \"dim_x\": dims[0],\n",
    "        \"dim_y\": dims[1],\n",
    "        \"dim_z\": dims[2],\n",
    "        \"voxel_x_mm\": voxel_sizes[0],\n",
    "        \"voxel_y_mm\": voxel_sizes[1],\n",
    "        \"voxel_z_mm\": voxel_sizes[2],\n",
    "        \"file_size_mb\": file_size_mb,\n",
    "        # Metadata (JSON sidecar)\n",
    "        \"tesla\": sidecar.get(\"MagneticFieldStrength\"),\n",
    "        \"manufacturer\": sidecar.get(\"Manufacturer\"),\n",
    "        \"model\": sidecar.get(\"ManufacturersModelName\"),\n",
    "        \"TR\": sidecar.get(\"RepetitionTime\"),\n",
    "        \"TE\": sidecar.get(\"EchoTime\"),\n",
    "        \"flip_angle\": sidecar.get(\"FlipAngle\"),\n",
    "    }\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def efc(img, framemask=None, decimals=4):\n",
    "    r\"\"\"\n",
    "    Calculate the :abbr:`EFC (Entropy Focus Criterion)` [Atkinson1997]_.\n",
    "    Uses the Shannon entropy of voxel intensities as an indication of ghosting\n",
    "    and blurring induced by head motion. A range of low values is better,\n",
    "    with EFC = 0 for all the energy concentrated in one pixel.\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\text{E} = - \\sum_{j=1}^N \\frac{x_j}{x_\\text{max}}\n",
    "        \\ln \\left[\\frac{x_j}{x_\\text{max}}\\right]\n",
    "\n",
    "    with :math:`x_\\text{max} = \\sqrt{\\sum_{j=1}^N x^2_j}`.\n",
    "\n",
    "    The original equation is normalized by the maximum entropy, so that the\n",
    "    :abbr:`EFC (Entropy Focus Criterion)` can be compared across images with\n",
    "    different dimensions:\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\text{EFC} = \\left( \\frac{N}{\\sqrt{N}} \\, \\log{\\sqrt{N}^{-1}} \\right) \\text{E}\n",
    "\n",
    "    :param numpy.ndarray img: input data\n",
    "    :param numpy.ndarray framemask: a mask of empty voxels inserted after a rotation of\n",
    "      data\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if framemask is None:\n",
    "        framemask = np.zeros_like(img, dtype=np.uint8)\n",
    "\n",
    "    n_vox = np.sum(1 - framemask)\n",
    "    # Calculate the maximum value of the EFC (which occurs any time all\n",
    "    # voxels have the same value)\n",
    "    efc_max = 1.0 * n_vox * (1.0 / np.sqrt(n_vox)) * np.log(1.0 / np.sqrt(n_vox))\n",
    "\n",
    "    # Calculate the total image energy\n",
    "    b_max = np.sqrt((img[framemask == 0] ** 2).sum())\n",
    "\n",
    "    # Calculate EFC (add 1e-16 to the image data to keep log happy)\n",
    "    return round(\n",
    "        float(\n",
    "            (1.0 / efc_max)\n",
    "            * np.sum(\n",
    "                (img[framemask == 0] / b_max)\n",
    "                * np.log((img[framemask == 0] + 1e-16) / b_max)\n",
    "            ),\n",
    "        ),\n",
    "        decimals,\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_histogram(df, key, bins=20, dropna=True, eps=1e-8):\n",
    "    if key not in df.columns:\n",
    "        raise ValueError(f\"Key '{key}' not found in dataframe\")\n",
    "\n",
    "    data = df[key]\n",
    "\n",
    "    if dropna:\n",
    "        data = data.dropna()\n",
    "\n",
    "    if len(data) == 0:\n",
    "        print(f\"[WARN] No data available for '{key}'\")\n",
    "        return\n",
    "\n",
    "    # Attempt numeric conversion\n",
    "    is_numeric = True\n",
    "    try:\n",
    "        data = pd.to_numeric(data)\n",
    "    except (ValueError, TypeError):\n",
    "        is_numeric = False\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    if is_numeric:\n",
    "        data_min = data.min()\n",
    "        data_max = data.max()\n",
    "\n",
    "        # Zero or near-zero range â†’ constant value\n",
    "        if np.isclose(data_min, data_max, atol=eps):\n",
    "            plt.bar([str(round(float(data_min), 4))], [len(data)])\n",
    "            plt.xlabel(key)\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.title(f\"{key} (constant value)\")\n",
    "        else:\n",
    "            # Safe bin count\n",
    "            effective_bins = min(bins, len(data))\n",
    "            plt.hist(data, bins=effective_bins)\n",
    "            plt.xlabel(key)\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.title(f\"Histogram of {key}\")\n",
    "    else:\n",
    "        # Categorical fallback\n",
    "        counts = data.value_counts()\n",
    "        plt.bar(counts.index.astype(str), counts.values)\n",
    "        plt.xlabel(key)\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.title(f\"Distribution of {key}\")\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0debe30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_path = \"/run/media/falconnier/Elements/datasets/BIDS_datasets/HypnosisBarrios\"  # <-- CHANGE THIS\n",
    "bids_path = \"/home/falconnier/Downloads/CamCAN\"  # <-- CHANGE THIS\n",
    "\n",
    "t1w_files = find_t1w_images(bids_path)[:15]\n",
    "print(f\"Found {len(t1w_files)} T1w images\")\n",
    "\n",
    "records = []\n",
    "for t1w in t1w_files:\n",
    "    records.append(extract_t1w_stats(t1w))\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1260d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute QC metrics that do not require any mask or preprocessing\n",
    "# from scipy.stats import kurtosis, skew\n",
    "\n",
    "\n",
    "# def compute_maskless_metrics(nifti_path, hist_bins=256):\n",
    "#     img = nib.load(str(nifti_path)).get_fdata()\n",
    "#     data = np.nan_to_num(img, nan=0.0, posinf=0.0, neginf=0.0).reshape(-1)\n",
    "#     # keep only finite values\n",
    "#     data = data[np.isfinite(data)]\n",
    "#     if data.size == 0:\n",
    "#         return {\"path\": str(nifti_path), \"error\": \"empty image\"}\n",
    "\n",
    "#     nz = data[data != 0]\n",
    "#     # robust mad (median absolute deviation)\n",
    "#     mad_val = float(np.median(np.abs(data - np.median(data))))\n",
    "\n",
    "#     # histogram-based entropy\n",
    "#     hist, _ = np.histogram(data, bins=hist_bins, density=True)\n",
    "#     probs = hist[hist > 0]\n",
    "#     entropy = float(-np.sum(probs * np.log2(probs))) if probs.size else 0.0\n",
    "\n",
    "#     out = {\n",
    "#         \"path\": str(nifti_path),\n",
    "#         \"n_voxels\": int(data.size),\n",
    "#         \"n_nonzero\": int((data != 0).sum()),\n",
    "#         \"nonzero_frac\": float((data != 0).mean()),\n",
    "#         \"mean\": float(np.mean(data)),\n",
    "#         \"median\": float(np.median(data)),\n",
    "#         \"std\": float(np.std(data)),\n",
    "#         \"mad\": mad_val,\n",
    "#         \"kurtosis\": float(kurtosis(data)),\n",
    "#         \"skewness\": float(skew(data)),\n",
    "#         \"p01\": float(np.percentile(data, 1)),\n",
    "#         \"p05\": float(np.percentile(data, 5)),\n",
    "#         \"p95\": float(np.percentile(data, 95)),\n",
    "#         \"p99\": float(np.percentile(data, 99)),\n",
    "#         \"entropy\": entropy,\n",
    "#     }\n",
    "#     # EFC from anatomical (works on whole image)\n",
    "#     try:\n",
    "#         out[\"efc\"] = float(efc(img))\n",
    "#     except Exception:\n",
    "#         out[\"efc\"] = None\n",
    "\n",
    "#     return out\n",
    "\n",
    "\n",
    "# # Compute for discovered T1w files and merge with existing dataframe\n",
    "# qc_records = [compute_maskless_metrics(p) for p in t1w_files]\n",
    "# df_qc_maskless = pd.DataFrame(qc_records)\n",
    "# df = df.merge(df_qc_maskless, on=\"path\", how=\"left\")\n",
    "# df.head()\n",
    "# df_qc_maskless.describe()\n",
    "# print(df_qc_maskless.loc[df_qc_maskless[\"efc\"].idxmin(), \"path\"])\n",
    "# print(df_qc_maskless.loc[df_qc_maskless[\"efc\"].idxmax(), \"path\"])\n",
    "# print(df_qc_maskless.loc[df_qc_maskless[\"entropy\"].idxmin(), \"path\"])\n",
    "# print(df_qc_maskless.loc[df_qc_maskless[\"entropy\"].idxmax(), \"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264e7d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"n_subjects\": df[\"subject\"].nunique(),\n",
    "    \"n_sessions\": df[\"session\"].nunique(),\n",
    "    \"n_t1w\": len(df),\n",
    "    \"voxel_sizes_mm\": df[[\"voxel_x_mm\", \"voxel_y_mm\", \"voxel_z_mm\"]].drop_duplicates(),\n",
    "    \"tesla_values\": df[\"tesla\"].value_counts(dropna=False),\n",
    "    \"manufacturers\": df[\"manufacturer\"].value_counts(dropna=False),\n",
    "}\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e1052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"voxel_x_mm\", \"voxel_y_mm\", \"voxel_z_mm\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect mixed resolutions\n",
    "df.groupby([\"voxel_x_mm\", \"voxel_y_mm\", \"voxel_z_mm\"]).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect scanner heterogeneity\n",
    "df.groupby([\"manufacturer\", \"model\", \"tesla\"]).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fea9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(df, \"voxel_z_mm\")\n",
    "plot_histogram(df, \"voxel_x_mm\")\n",
    "plot_histogram(df, \"voxel_y_mm\")\n",
    "plot_histogram(df, \"file_size_mb\")\n",
    "plot_histogram(df, \"tesla\", bins=5)\n",
    "plot_histogram(df, \"dim_z\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
